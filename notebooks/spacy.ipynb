{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed7e94da",
   "metadata": {},
   "source": [
    "#### Script for reading and storing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3a9406",
   "metadata": {},
   "source": [
    "idea being - instead of loading all text passages in memory  with f.open(), stream data and only store limited passages in mem\n",
    "\n",
    "\n",
    "use generators: generator.next() gives me the passage, for loop handles this automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b91aaf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 2334k  100 2334k    0     0  7634k      0 --:--:-- --:--:-- --:--:-- 7634k\n",
      "Archive:  dataset.zip\n",
      "replace 01 Harry Potter and the Sorcerers Stone.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
     ]
    }
   ],
   "source": [
    "!curl -L -o dataset.zip https://www.kaggle.com/api/v1/datasets/download/shubhammaindola/harry-potter-books\n",
    "!unzip dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6dc0c04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01 Harry Potter and the Sorcerers Stone.txt', '02 Harry Potter and the Chamber of Secrets.txt', '03 Harry Potter and the Prisoner of Azkaban.txt', '04 Harry Potter and the Goblet of Fire.txt', '05 Harry Potter and the Order of the Phoenix.txt', '06 Harry Potter and the Half-Blood Prince.txt', '07 Harry Potter and the Deathly Hallows.txt']\n"
     ]
    }
   ],
   "source": [
    "paths = !ls | grep \".txt\"\n",
    "book_1 = paths[0]\n",
    "print(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b046c8a",
   "metadata": {},
   "source": [
    "#### Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "141e7f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "287f3cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_passages(file_path,context_size=1024):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        buffer = \"\"\n",
    "        for line in f:\n",
    "            buffer += line\n",
    "        while len(buffer) > context_size:\n",
    "            yield buffer[:context_size]\n",
    "            buffer = buffer[context_size:]\n",
    "        if buffer:\n",
    "            yield buffer\n",
    "\n",
    "def analyze_text(text:str,nlp,df:pd.DataFrame=None) -> pd.DataFrame:\n",
    "    doc = nlp(text)\n",
    "    rows = []\n",
    "\n",
    "    for token in doc:\n",
    "        rows.append({\n",
    "            \"token\":token.text,\n",
    "            \"POS\":token.pos_,\n",
    "            \"ENT\":token.ent_type_\n",
    "        })\n",
    "\n",
    "    df_rows = pd.DataFrame(rows)\n",
    "    if df is None:\n",
    "        return df_rows\n",
    "    else:\n",
    "        df = pd.concat([df, df_rows], ignore_index=True)\n",
    "        return df\n",
    "    \n",
    "\n",
    "def process_corpora():\n",
    "    batch_data = stream_passages(book_1)\n",
    "    df = pd.DataFrame()\n",
    "    for batches in batch_data:\n",
    "        df = analyze_text(batches,nlp,df)\n",
    "\n",
    "    df.to_csv(\"output.csv\", index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07af61b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_corpora()\n",
    "!cat output.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6fbfb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
